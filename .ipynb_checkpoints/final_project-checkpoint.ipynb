{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMBdGcvjC4Ji"
   },
   "source": [
    "# Итоговый проект по курсу \"Рекомендательные системы\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5Aur99NsC4Jm",
    "outputId": "9b9a338b-a52f-4253-9694-ac431b62eefc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# Метрики\n",
    "from best_rec_lib.metrics import precision_at_k, recall_at_k, ap_k\n",
    "\n",
    "# Префильтрация, работа с фичами, предсказания\n",
    "from best_rec_lib.utils import trainValLvl1Split, prefilter_items, trainTestDf, getRecommendationsLvl2\n",
    "\n",
    "# Класс рекомендера\n",
    "from best_rec_lib.recommenders import MainRecommender\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vso_erSdC4Jo",
    "outputId": "da20dbf1-3086-4fd6-ac92-f7653d7f9f71"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../retail_train.csv')\n",
    "item_features = pd.read_csv('../product.csv')\n",
    "user_features = pd.read_csv('../hh_demographic.csv')\n",
    "data_test = pd.read_csv('../retail_test.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим данные на трейнировочную и валидационную выборки для модели 1го уровня. В них попадут только заказы для user_id, которые есть в тестовой выборке retail_test.csv, **остальные данные не берем.** Данные делил не по неделям, для валидации используем посление 10% заказов для каждого пользователя, остальное - трейн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_ids = list(set(data_test.user_id))\n",
    "\n",
    "# Для иодели 1го уровння\n",
    "data_train_lvl_1, data_val_lvl_1 = trainValLvl1Split(data, test_user_ids)\n",
    "\n",
    "# Для иодели 2го уровння\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()\n",
    "data_val_lvl_2 = data_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Производим префильтрацию айтемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zcnV3l4XC4Jp",
    "outputId": "d58f889c-0671-4bb9-b2b6-2dc2e8c24fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество айтемов сокращено с 78673 до 3301\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "# Берем топ3300. При топ3000 MAP@5 немного выше, но при топ3300 самый высокий Precision@5 на модели lvl2\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=3300)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Количество айтемов сокращено с {} до {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAHJu3Z5C4Ju"
   },
   "source": [
    "#### Модель 1го уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ce567b5a0a4ca78b046ace220a8efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea184f81369f4468b06f0a0dcc963954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.92 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем списки рекомендаций для пользователей моделью 1го уровня в количестве 500 штук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XZQcrch7C4Ju"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n",
    "\n",
    "# Получим предсказания. Пробовал комбинировать предсказания нескольких моделей - не сработало\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим метрики модели 1го уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result.columns=['user_id', 'actual']\n",
    "result = result.merge(users_lvl_2, on='user_id', how='left')\n",
    "result.loc[result['candidates'].isnull(), 'candidates'] = result.loc[result['candidates'].isnull(), 'user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k:  0.30743099787685674\n",
      "MAP@k:  0.22930644019815977\n",
      "Recall@k:  0.1800660499707142\n"
     ]
    }
   ],
   "source": [
    "print('Precision@k: ', result.apply(lambda row: precision_at_k(row['candidates'], row['actual'], 5), axis=1).mean())\n",
    "print('MAP@k: ', result.apply(lambda row: ap_k(row['candidates'], row['actual'], 5), axis=1).mean())\n",
    "print('Recall@k: ', result.apply(lambda row: recall_at_k(row['candidates'], row['actual'], 500), axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Собираем датафрейм для обучения модели 2го уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "targets_lvl_2.drop('flag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Собираем датасет для создания фичей для модели 2го уровня**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем и берем без предобработки\n",
    "data_train = data_train_lvl_1.append(data_val_lvl_1, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавляем в него фичи:\n",
    "1. Для пользователя:\n",
    "- средний чек пользователя\n",
    "- средний чек пользователя по категориям товаров\n",
    "- максимальный чек пользователя\n",
    "- максимальный чек пользователя по категориям товаров\n",
    "2. Для товара:\n",
    "- мода возрастной категории, приобретающих товар\n",
    "- мода категории дохода, приобретающих товар\n",
    "- доля заказов в которых есть айтем\n",
    "3. Для пары user-товар:\n",
    "- среднее количество покупок пользователями товаров данной категории\n",
    "- средний чек всех пользователей по категории товара\n",
    "- сумма покупок пользователем товара\n",
    "- количество раз покупоки пользователем товара\n",
    "- общее количество единиц товара купленного пользователем\n",
    "- количество дней с момента последней покупки пользователем товара\n",
    "\n",
    "**А так же делим на трейн-тест.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train, cat_feats = trainTestDf(data_train, targets_lvl_2, item_features, user_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучаем модель классификации и получаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lvl_2 = targets_lvl_2[['user_id', 'item_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 18min 52s\n",
      "Wall time: 12min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Используется CatBoostClassifier. Модель LGBMClassifier показала результат по метрике MAP@5 на ~3% хуже,\n",
    "# но ее обучение занимает 6 сек вместо 12 минут.\n",
    "preds_lvl_2['pred_proba'] = recommender.get_classification_lvl2_preds(X_train, y_train, cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result.columns=['user_id', 'actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В тестовом дата сете 1885 юзеров\n",
      "В тестовом дата сете 4 новых юзеров\n"
     ]
    }
   ],
   "source": [
    "test_users = result.shape[0]\n",
    "new_test_users = len(set(result['user_id']) - set(preds_lvl_2['user_id']))\n",
    "\n",
    "print('В тестовом дата сете {} юзеров'.format(test_users))\n",
    "print('В тестовом дата сете {} новых юзеров'.format(new_test_users))\n",
    "new_test_users = list(set(result['user_id']) - set(preds_lvl_2['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['classification_rec'] = result['user_id'].map(lambda x: getRecommendationsLvl2(preds_lvl_2, x, recommender, N=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассчитаем метрики результата работы моделей lvl1 + lvl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k:  0.37082228116710947\n",
      "MAP@k:  0.3284350132625996\n",
      "Recall@k:  0.058229070157084145\n"
     ]
    }
   ],
   "source": [
    "print('Precision@k: ', result.apply(lambda row: precision_at_k(row['classification_rec'], row['actual'], 5), axis=1).mean())\n",
    "print('MAP@k: ', result.apply(lambda row: ap_k(row['classification_rec'], row['actual'], 5), axis=1).mean())\n",
    "print('Recall@k: ', result.apply(lambda row: recall_at_k(row['classification_rec'], row['actual'], 5), axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получили MAP@5 = 0.3284350132625996"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сохраняем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбцы: user_id, actual, classification_rec\n",
    "result.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_webinar_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
